"""
119 ì‘ê¸‰ì‹ ê³  ì˜ˆì¸¡ ì‹œìŠ¤í…œ ë©”ì¸ íŒŒì´í”„ë¼ì¸
"""

import time
import pandas as pd
import numpy as np
from typing import Tuple

# í”„ë¡œì íŠ¸ ëª¨ë“ˆë“¤ import
# ì²˜ìŒì—ëŠ” ë‹¤ í•œ íŒŒì¼ì— ìˆì—ˆëŠ”ë° ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›Œì„œ ë¶„ë¦¬í•¨
from src.config.settings import Config
from src.data.data_loader import DataLoader  # ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ë‹´ë‹¹
from src.features.feature_engineer import FeatureEngineer  # í”¼ì²˜ ìƒì„± (ì›ë³¸ ë°ì´í„° weekday ì˜¤ë¥˜ í•´ê²° í¬í•¨)
from src.features.stats_holder import StatsHolder  # í†µê³„ í”¼ì²˜ë“¤ (ê±°ë¦¬, í´ëŸ¬ìŠ¤í„° ë“±)
from src.features.pca_holder import PCAHolder  # PCA ì²˜ë¦¬ (ê²°êµ­ ì•ˆ ì“°ê¸°ë¡œ í–ˆì§€ë§Œ í˜¹ì‹œ ëª°ë¼ì„œ ë‚¨ê²¨ë‘ )
from src.features.smart_feature_selector import SmartFeatureSelector  # ìŠ¹ì •ë‹˜ ì œì•ˆ: Elastic Net ìë™ ë³€ìˆ˜ì„ íƒ
from src.models.model_trainer import ModelTrainer  # ëª¨ë¸ í›ˆë ¨ ë° ê´€ë¦¬
from src.models.ensemble_model import EnsembleModel  # ì•™ìƒë¸” ëª¨ë¸ (ì—¬ëŸ¬ ëª¨ë¸ ê²°í•©)
from src.utils.evaluation import print_model_comparison, save_evaluation_results  # ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
from src.utils.variable_tracker import VariableTracker  # íˆ¬ëª…ì„± í™•ë³´ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì¶”ì 
from src.utils.visualization import (  # ì‹œê°í™” ìœ í‹¸ë¦¬í‹°ë“¤
    create_model_report_plots, plot_model_comparison, plot_predictions_vs_actual,
    save_feature_importance
)


def create_features(df, is_train=True, stats_holder=None, pca_holder=None, config=None):
    """
    í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ íŒŒì´í”„ë¼ì¸
    
    ì²˜ìŒì—ëŠ” ëª¨ë“  í”¼ì²˜ë¥¼ í•œë²ˆì— ë§Œë“¤ë ¤ê³  í–ˆëŠ”ë°, ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ”
    train/testì—ì„œ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©ë˜ë„ë¡ stats_holderì™€ pca_holder ì¬ì‚¬ìš©
    """
    print(f"í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘ ({'í›ˆë ¨' if is_train else 'í…ŒìŠ¤íŠ¸'} ë°ì´í„°)")
    
    start_time = time.time()
    
    # ê¸°ë³¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ì‹œê°„, ë‚ ì”¨, lag/rolling ë“±)
    # ë°•ë¯¼í˜œë‹˜ ì§€ì ì‚¬í•­: ì›ë³¸ ë°ì´í„° weekday ì˜¤ë¥˜ ë¬¸ì œ í•´ê²°ë¨
    fe = FeatureEngineer()
    df_featured = fe.engineer_all_features(
        df, 
        lag_days=config.LAG_DAYS,      # [1, 3, 7] - 1ì¼, 3ì¼, 7ì¼ ì „ ë°ì´í„°
        windows=config.ROLLING_WINDOWS, # [3, 7, 14] - ë¡¤ë§ ìœˆë„ìš° í¬ê¸°ë“¤
        weather_cols=config.WEATHER_FEATURES  # ë‚ ì”¨ ìƒí˜¸ì‘ìš© í”¼ì²˜ìš© ì»¬ëŸ¼ë“¤
    )
    
    # í†µê³„ì  í”¼ì²˜ë“¤ (ê±°ë¦¬, í´ëŸ¬ìŠ¤í„°, ë„¤íŠ¸ì›Œí¬ ë“±)
    # ì´ ë¶€ë¶„ì´ ì‹œê°„ì´ ì œì¼ ì˜¤ë˜ ê±¸ë¦¼ (íŠ¹íˆ ë„¤íŠ¸ì›Œí¬ í”¼ì²˜)
    if is_train:
        stats_holder = StatsHolder(
            city_coords=config.CITY_COORDINATES,  # ë¶€ì‚° ì¤‘ì‹¬ ì¢Œí‘œ
            coast_lat=config.COAST_LAT  # ìœ„í‚¤ì—ì„œ ì°¾ì€ ì¢Œí‘œ (ê±°ë¦¬ ê³„ì‚°ìš©)
        )
        stats_holder.fit(df_featured)  # train ë°ì´í„°ë¡œ í†µê³„ í•™ìŠµ
    
    # testì—ì„œëŠ” trainì—ì„œ í•™ìŠµí•œ í†µê³„ ì ìš©
    df_featured = stats_holder.transform(df_featured)
    
    # PCA í”¼ì²˜ (íš¨ê³¼ ì—†ì–´ì„œ ê¸°ë³¸ê°’ False)
    # í•˜ì§€ë§Œ í˜¹ì‹œ ë‚˜ì¤‘ì— ì‹¤í—˜í•´ë³¼ ìˆ˜ ìˆê²Œ ì½”ë“œëŠ” ë‚¨ê²¨ë‘ 
    if config.USE_PCA:
        # call_countëŠ” targetì´ë¯€ë¡œ PCAì—ì„œ ì œì™¸
        numeric_cols = df_featured.select_dtypes(include=[np.number]).columns.tolist()
        numeric_cols = [c for c in numeric_cols if c not in ['call_count']]
        
        if is_train:
            pca_holder = PCAHolder(n_components=config.PCA_COMPONENTS)
            pca_holder.fit(df_featured, numeric_cols)
        
        df_featured = pca_holder.transform(df_featured)
        print(f"PCA í”¼ì²˜ {config.PCA_COMPONENTS}ê°œ ì¶”ê°€ë¨")
    else:
        print("PCA í”¼ì²˜ ì‚¬ìš© ì•ˆí•¨")
    
    elapsed = time.time() - start_time
    print(f"í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ. ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    
    return df_featured, stats_holder, pca_holder


def main():
    """
    ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("="*80)
    print("119 Call Prediction Pipeline ì‹œì‘")
    print("="*80)
    
    total_start_time = time.time()
    
    # ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸° (settings.pyì—ì„œ ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê´€ë¦¬)
    config = Config()
    
    # íˆ¬ëª…ì„± í™•ë³´ë¥¼ ìœ„í•œ ë³€ìˆ˜ ì¶”ì ê¸° ì´ˆê¸°í™”
    tracker = VariableTracker()
    print("âœ… ë³€ìˆ˜ ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ì¶œë ¥ í´ë”ë“¤ ìƒì„± í™•ì¸
    import os
    os.makedirs(config.OUTPUT_DIR, exist_ok=True)
    os.makedirs(f"{config.OUTPUT_DIR}/plots", exist_ok=True)
    print(f"ğŸ“ ì¶œë ¥ í´ë” ì¤€ë¹„ ì™„ë£Œ: {config.OUTPUT_DIR}/")
    
    # 1. ë°ì´í„° ë¡œë”©
    # UTF-8 ì¸ì½”ë”© ë¬¸ì œë¡œ í•œì°¸ ê³ ìƒí–ˆì—ˆìŒ (ì›ë³¸ì´ EUC-KRì´ì—ˆìŒ)
    print("\n1. ë°ì´í„° ë¡œë”©")
    data_loader = DataLoader(config.DATA_FILE, config.ENCODING)
    data = data_loader.load_data()
    
    # 2. ì‹œê³„ì—´ ê¸°ë°˜ train/test ë¶„í• 
    # 2020-2022ë…„: train, 2023ë…„: test (ë¯¸ë˜ ì˜ˆì¸¡ì´ë¯€ë¡œ)
    print("\n2. Train/Test ë¶„í• ")
    train_df, test_df = data_loader.split_train_test(config.TRAIN_YEARS, config.TEST_YEARS)
    
    # 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ê°€ì¥ ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ë¶€ë¶„)
    # trainê³¼ testì— ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©ë˜ë„ë¡ ì£¼ì˜
    print("\n3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
    train_featured, stats_holder, pca_holder = create_features(train_df, is_train=True, config=config)
    test_featured, _, _ = create_features(test_df, is_train=False, 
                                        stats_holder=stats_holder,  # trainì—ì„œ í•™ìŠµëœ í†µê³„ ì¬ì‚¬ìš©
                                        pca_holder=pca_holder,      # trainì—ì„œ í•™ìŠµëœ PCA ì¬ì‚¬ìš©
                                        config=config)
    
    # í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í›„ ë³€ìˆ˜ ëª©ë¡ ì¶”ì  ì €ì¥
    tracker.save_initial_variables(train_featured, "after_feature_engineering")
    print(f"ğŸ“Š í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê²°ê³¼: {len(train_featured.columns)}ê°œ ë³€ìˆ˜ ìƒì„±")
    
    # 4. í”¼ì²˜ ì„ íƒ
    # ê¸°ì¡´: ìƒê´€ê´€ê³„ ì„ê³„ê°’ë§Œ ì‚¬ìš© â†’ 53ê°œ ê³ ìƒê´€ ë³€ìˆ˜ìŒìœ¼ë¡œ ë‹¤ì¤‘ê³µì„ ì„± ì‹¬ê°
    # ê°œì„ : Elastic Netìœ¼ë¡œ ìë™ ë³€ìˆ˜ì„ íƒ â†’ ë‹¤ì¤‘ê³µì„ ì„± ê·¼ë³¸ í•´ê²°
    print("\n4. í”¼ì²˜ ì„ íƒ")
    print("ë†’ì€ ìƒê´€ê´€ê³„ ë³€ìˆ˜ìŒì´ ë„ˆë¬´ ë§ì•„ì„œ Elastic Net ë¨¼ì € ì ìš©")
    
    # SmartFeatureSelectorë¡œ Elastic Net ê¸°ë°˜ ë³€ìˆ˜ì„ íƒ
    selector = SmartFeatureSelector(correlation_threshold=config.CORRELATION_THRESHOLD)
    
    # Elastic Net + ìƒê´€ê´€ê³„ ì •ì œ ê²°í•©
    final_features, selection_results = selector.combined_selection(
        train_featured, 
        target_col='call_count',
        use_elastic_net=True,    # ì—˜ë¼ìŠ¤í‹± ë„· ì‚¬ìš© ì—¬ë¶€
        use_correlation=False    # Elastic Netì´ë©´ ì¶©ë¶„í•¨ (ì¤‘ë³µ ì œê±° ë°©ì§€)
    )
    
    # ê²°ê³¼ ì €ì¥ (íˆ¬ëª…ì„± í™•ë³´)
    if selection_results['elastic_net_results']:
        selector.save_analysis_results(
            selection_results['elastic_net_results'], 
            output_prefix="elastic_net_selection"
        )
    
    # ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ë¥¼ trackerì— ì €ì¥ (íˆ¬ëª…ì„± ê°•í™”)
    if hasattr(selector, 'correlation_matrix') and selector.correlation_matrix is not None:
        removed_vars = [col for col in train_featured.select_dtypes(include=[np.number]).columns 
                       if col not in final_features and col != 'call_count']
        tracker.save_correlation_analysis(
            selector.correlation_matrix, 
            config.CORRELATION_THRESHOLD,
            removed_vars, 
            final_features
        )
    
    # train/testì— ë™ì¼í•œ í”¼ì²˜ ì ìš©
    final_features_with_target = final_features + ['call_count']
    train_cleaned = train_featured[final_features_with_target].copy()
    test_cleaned = test_featured[final_features_with_target].copy()
    
    print(f"   Elastic Net ê¸°ë°˜ ìµœì¢… ì„ íƒ: {len(final_features)}ê°œ ë³€ìˆ˜")
    
    # ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ ëª©ë¡ ì €ì¥
    tracker.save_initial_variables(train_cleaned, "after_feature_selection")
    
    # 5. ëª¨ë¸ë§ìš© ë°ì´í„° ì¤€ë¹„
    feature_cols = final_features  # Elastic Netìœ¼ë¡œ ì„ íƒëœ í”¼ì²˜ë“¤
    X_train = data_loader.clean_features(train_cleaned[feature_cols])  # inf, nan ì²˜ë¦¬
    y_train = train_cleaned['call_count']
    X_test = data_loader.clean_features(test_cleaned[feature_cols])
    y_test = test_cleaned['call_count']
    
    print(f"ìµœì¢… í”¼ì²˜ ìˆ˜: {len(feature_cols)} (Elastic Net ì„ íƒ)")
    
    # 6. ëª¨ë¸ í›ˆë ¨ (4ê°œ ëª¨ë¸ ë™ì‹œ í›ˆë ¨)
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ì´ì „ ì‹¤í—˜ë“¤ì„ í†µí•´ íŠœë‹ëœ ê°’ë“¤
    print("\n5. ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€")
    trainer = ModelTrainer()
    trainer.train_all_models(X_train, y_train, 
                           rf_params=config.RF_PARAMS,       # RandomForest íŒŒë¼ë¯¸í„°
                           lgbm_params=config.LGBM_PARAMS,   # LightGBM íŒŒë¼ë¯¸í„°  
                           xgb_params=config.XGB_PARAMS,     # XGBoost íŒŒë¼ë¯¸í„°
                           cat_params=config.CATBOOST_PARAMS) # CatBoost íŒŒë¼ë¯¸í„°
    
    # 7. ëª¨ë¸ í‰ê°€ ë° ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„
    results = trainer.evaluate_all_models(X_test, y_test)
    
    # ê° ëª¨ë¸ì˜ ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ trackerì— ì €ì¥ (íˆ¬ëª…ì„± ê°•í™”)
    print("\nğŸ“ˆ ëª¨ë¸ë³„ ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„ ë° ì €ì¥")
    model_predictions = {}
    
    for model_name in ['RandomForest', 'LightGBM', 'XGBoost', 'CatBoost']:
        if model_name in trainer.models:
            model = trainer.models[model_name]
            predictions = model.predict(X_test)
            model_predictions[model_name] = predictions
            
            # ë³€ìˆ˜ ì¤‘ìš”ë„ ì €ì¥
            tracker.save_model_importance(
                model_name, model, feature_cols, X_test, y_test, predictions
            )
            
            # ê°œë³„ ëª¨ë¸ ì‹œê°í™” ìƒì„±
            create_model_report_plots(y_test, predictions, model_name, f"{config.OUTPUT_DIR}/plots")
            
            # í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” (visualization.py í™œìš©)
            if hasattr(model, 'feature_importances_'):
                importance_series = pd.Series(model.feature_importances_, index=feature_cols).sort_values(ascending=False)
                save_feature_importance(importance_series, f"{config.OUTPUT_DIR}/{model_name}_feature_importance.png", 
                                       f"{model_name} Feature Importance", top_n=20)
    
    # 8. ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ë° í‰ê°€
    print("\nğŸ”€ ì•™ìƒë¸” ëª¨ë¸ ìƒì„± ë° í‰ê°€")
    ensemble = EnsembleModel()
    
    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ ì•™ìƒë¸”ì— ì¶”ê°€
    for model_name, predictions in model_predictions.items():
        ensemble.add_predictions(model_name, predictions)
    
    # ì—¬ëŸ¬ ì•™ìƒë¸” ë°©ë²• ë¹„êµ
    ensemble_comparison = ensemble.compare_ensemble_methods(y_test)
    print("\nì•™ìƒë¸” ì„±ëŠ¥ ë¹„êµ:")
    print(ensemble_comparison)
    
    # ìµœê³  ì„±ëŠ¥ ì•™ìƒë¸” ë°©ë²• ì„ íƒ
    best_ensemble_method = ensemble_comparison.loc[ensemble_comparison['rmse'].idxmin(), 'method']
    print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ì•™ìƒë¸” ë°©ë²•: {best_ensemble_method}")
    
    # ìµœì  ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„±
    if best_ensemble_method == 'Simple Average':
        best_ensemble_pred = ensemble.predict_simple_average()
    elif best_ensemble_method == 'RMSE Weighted':
        best_weights = ensemble.get_best_weights_by_performance(y_test, 'rmse')
        best_ensemble_pred = ensemble.predict_weighted_average(best_weights)
    else:  # RÂ² Weighted
        best_weights = ensemble.get_best_weights_by_performance(y_test, 'r2')
        best_ensemble_pred = ensemble.predict_weighted_average(best_weights)
    
    # ì•™ìƒë¸” ê²°ê³¼ë¥¼ resultsì— ì¶”ê°€
    ensemble_metrics = ensemble.evaluate_ensemble(y_test, best_ensemble_pred)
    results[f'Ensemble_{best_ensemble_method.replace(" ", "_")}'] = ensemble_metrics
    
    # ì•™ìƒë¸” ì‹œê°í™”
    create_model_report_plots(y_test, best_ensemble_pred, f'Ensemble_{best_ensemble_method}', f"{config.OUTPUT_DIR}/plots")
    
    # 9. ê²°ê³¼ ì¶œë ¥ (RMSE ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•´ì„œ ë³´ì—¬ì¤Œ)
    print("\nğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½ (ì•™ìƒë¸” í¬í•¨)")
    print_model_comparison(results)
    
    # ëª¨ë¸ ë¹„êµ ì°¨íŠ¸ ìƒì„±
    plot_model_comparison(results, f"{config.OUTPUT_DIR}/model_comparison.png")
    
    # 10. ê²°ê³¼ ì €ì¥ (CSV íŒŒì¼ë¡œ ì €ì¥í•´ì„œ ë‚˜ì¤‘ì— ë¶„ì„ ê°€ëŠ¥)
    save_evaluation_results(results, f"{config.OUTPUT_DIR}/evaluation_results.csv")
    
    # 11. ë³€ìˆ˜ ì¶”ì  ì¢…í•© ìš”ì•½ ìƒì„±
    print("\nğŸ“‹ ë³€ìˆ˜ ì„ íƒ ê³¼ì • ì¢…í•© ìš”ì•½ ìƒì„±")
    tracker.save_comprehensive_summary()
    
    # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ì¶œë ¥
    total_elapsed = time.time() - total_start_time
    print(f"\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {total_elapsed:.2f}ì´ˆ")
    print(f"ğŸ“ ëª¨ë“  ê²°ê³¼ íŒŒì¼ì´ {config.OUTPUT_DIR}/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
    print(f"   - í‰ê°€ ê²°ê³¼: evaluation_results.csv")
    print(f"   - ë³€ìˆ˜ ë¶„ì„: comprehensive_feature_analysis.csv")
    print(f"   - ëª¨ë¸ ì‹œê°í™”: plots/ í´ë”")
    print(f"   - í”¼ì²˜ ì¤‘ìš”ë„: *_feature_importance.png")
    
    # ìµœì¢… ë² ìŠ¤íŠ¸ ëª¨ë¸ ì¶œë ¥
    if results:
        best_model = min(results.items(), key=lambda x: x[1]['rmse'])
        print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model[0]} (RMSE: {best_model[1]['rmse']:.3f}, RÂ²: {best_model[1]['r2']:.3f})")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    main()
