"""Smart feature selection module with domain knowledge integration."""

import pandas as pd
import numpy as np
from typing import List, Tuple, Dict, Any
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')


class SmartFeatureSelector:
    """
    ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ë³€ìˆ˜ ì„ íƒ í´ë˜ìŠ¤.
    
    **ì£¼ìš” ê¸°ëŠ¥:**
    - ìƒê´€ê´€ê³„ ê¸°ë°˜ ë³€ìˆ˜ ì œê±° ì‹œ ë„ë©”ì¸ ì§€ì‹ ì ìš©
    - ê¸°ìƒ ë³€ìˆ˜ ìš°ì„  ë³´ì¡´ ì •ì±…
    - íˆ¬ëª…í•œ ì„ íƒ ê³¼ì • ì¶”ì 
    - íŒ€ì› ë…¼ì˜ ì‚¬í•­ ë°˜ì˜
    """
    
    def __init__(self, correlation_threshold: float = 0.85):
        self.correlation_threshold = correlation_threshold
        self.domain_priorities = {
            'weather_original': ['ta_max', 'ta_min', 'ws_max', 'hm_max', 'hm_min', 'rn_day'],
            'target': ['call_count'],
            'temporal_basic': ['year', 'month', 'day', 'weekday'],
            'population': ['ì´ì¸êµ¬ìˆ˜', 'ì„¸ëŒ€ìˆ˜', 'ë‚¨ì.ì¸êµ¬ìˆ˜', 'ì—¬ì.ì¸êµ¬ìˆ˜'],
            'location': ['xcoord', 'ycoord'],
            'derived_important': ['temp_avg', 'humidity_avg', 'is_rainy', 'is_weekend']
        }
        self.removal_log = []
        self.selection_log = []
    
    def select_better_variable(self, var1: str, var2: str, correlation_val: float) -> str:
        """
        ë‘ ë³€ìˆ˜ ì¤‘ ì œê±°í•  ë³€ìˆ˜ë¥¼ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ìœ¼ë¡œ ì„ íƒ.
        
        **ìš°ì„ ìˆœìœ„ ê·œì¹™:**
        1. ê¸°ìƒ ì›ë³¸ ë³€ìˆ˜ > íŒŒìƒ ë³€ìˆ˜
        2. ì§§ì€ ì´ë¦„ > ê¸´ ì´ë¦„ (ë‹¨ìˆœì„±)
        3. ê¸°ë³¸ ë³€ìˆ˜ > ë³µì¡í•œ ìƒí˜¸ì‘ìš© ë³€ìˆ˜
        
        Args:
            var1: ì²« ë²ˆì§¸ ë³€ìˆ˜ëª…
            var2: ë‘ ë²ˆì§¸ ë³€ìˆ˜ëª…  
            correlation_val: ìƒê´€ê´€ê³„ ê°’
            
        Returns:
            ì œê±°í•  ë³€ìˆ˜ëª…
        """
        
        # 1. ê¸°ìƒ ì›ë³¸ ë³€ìˆ˜ ìš°ì„  ë³´ì¡´
        for category, variables in self.domain_priorities.items():
            if var1 in variables and var2 not in variables:
                self._log_selection(var1, var2, correlation_val, f"ë„ë©”ì¸ ìš°ì„ ìˆœìœ„: {category}")
                return var2
            elif var2 in variables and var1 not in variables:
                self._log_selection(var2, var1, correlation_val, f"ë„ë©”ì¸ ìš°ì„ ìˆœìœ„: {category}")
                return var1
        
        # 2. ë‘˜ ë‹¤ ê°™ì€ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ê±°ë‚˜ ë‘˜ ë‹¤ ì†í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        
        # py_weekday vs weekday íŠ¹ë³„ ì²˜ë¦¬
        if {var1, var2} == {'weekday', 'py_weekday'}:
            self._log_selection('weekday', 'py_weekday', correlation_val, "ì¤‘ë³µ ë³€ìˆ˜: weekday ìš°ì„ ")
            return 'py_weekday'
        
        # ë³µì¡í•œ íŒŒìƒ ë³€ìˆ˜ë³´ë‹¤ ë‹¨ìˆœí•œ ë³€ìˆ˜ ì„ í˜¸
        complex_patterns = ['interaction', 'poly', 'roll', 'lag', 'cluster', 'network']
        
        var1_complex = any(pattern in var1.lower() for pattern in complex_patterns)
        var2_complex = any(pattern in var2.lower() for pattern in complex_patterns)
        
        if var1_complex and not var2_complex:
            self._log_selection(var2, var1, correlation_val, "ë‹¨ìˆœì„± ìš°ì„ : ë³µì¡í•œ íŒŒìƒë³€ìˆ˜ ì œê±°")
            return var1
        elif var2_complex and not var1_complex:
            self._log_selection(var1, var2, correlation_val, "ë‹¨ìˆœì„± ìš°ì„ : ë³µì¡í•œ íŒŒìƒë³€ìˆ˜ ì œê±°")
            return var2
        
        # 3. ì´ë¦„ ê¸¸ì´ ê¸°ì¤€ (ë‹¨ìˆœì„±)
        if len(var1) != len(var2):
            if len(var1) < len(var2):
                self._log_selection(var1, var2, correlation_val, "ë‹¨ìˆœì„±: ì§§ì€ ë³€ìˆ˜ëª… ì„ í˜¸")
                return var2
            else:
                self._log_selection(var2, var1, correlation_val, "ë‹¨ìˆœì„±: ì§§ì€ ë³€ìˆ˜ëª… ì„ í˜¸")
                return var1
        
        # 4. ê¸°ë³¸ê°’: ì²« ë²ˆì§¸ ë³€ìˆ˜ ì œê±°
        self._log_selection("ë¬´ì‘ìœ„", f"{var1}>{var2}", correlation_val, "ê¸°ë³¸ ê·œì¹™")
        return var1
    
    def remove_correlated_features(self, df: pd.DataFrame, 
                                 exclude_columns: List[str] = None) -> Tuple[List[str], Dict[str, Any]]:
        """
        ìƒê´€ê´€ê³„ ê¸°ë°˜ ë³€ìˆ˜ ì œê±° (ë„ë©”ì¸ ì§€ì‹ ì ìš©).
        
        Args:
            df: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
            exclude_columns: ë¶„ì„ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ë“¤ (ì˜ˆ: target)
            
        Returns:
            (ìµœì¢…_ì„ íƒëœ_ë³€ìˆ˜_ë¦¬ìŠ¤íŠ¸, ìƒì„¸_ë¶„ì„_ê²°ê³¼)
        """
        
        print(f"\nğŸ” ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ìƒê´€ê´€ê³„ ë¶„ì„ (ì„ê³„ê°’: {self.correlation_threshold})")
        
        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì„ íƒ
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if exclude_columns:
            numeric_cols = [col for col in numeric_cols if col not in exclude_columns]
        
        print(f"   ğŸ“Š ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜: {len(numeric_cols)}ê°œ")
        
        # ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚°
        corr_matrix = df[numeric_cols].corr().abs()
        
        # ìƒì‚¼ê°í–‰ë ¬ì—ì„œ ë†’ì€ ìƒê´€ê´€ê³„ ìŒ ì°¾ê¸°
        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        
        to_remove = set()
        high_corr_pairs = []
        
        for i in range(len(upper.columns)):
            for j in range(len(upper.columns)):
                if pd.notna(upper.iloc[i, j]) and upper.iloc[i, j] > self.correlation_threshold:
                    var1, var2 = upper.columns[i], upper.columns[j]
                    corr_val = upper.iloc[i, j]
                    
                    high_corr_pairs.append({
                        'var1': var1,
                        'var2': var2, 
                        'correlation': corr_val
                    })
                    
                    # ë„ë©”ì¸ ì§€ì‹ìœ¼ë¡œ ì œê±°í•  ë³€ìˆ˜ ì„ íƒ
                    remove_var = self.select_better_variable(var1, var2, corr_val)
                    to_remove.add(remove_var)
        
        # ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ë“¤
        final_features = [col for col in numeric_cols if col not in to_remove]
        
        analysis_result = {
            'initial_count': len(numeric_cols),
            'removed_count': len(to_remove),
            'final_count': len(final_features),
            'high_corr_pairs': high_corr_pairs,
            'removed_variables': list(to_remove),
            'final_features': final_features,
            'selection_log': self.selection_log,
            'corr_matrix': corr_matrix
        }
        
        print(f"   âœ… ì œê±°ëœ ë³€ìˆ˜: {len(to_remove)}ê°œ")
        print(f"   âœ… ìµœì¢… ë³€ìˆ˜: {len(final_features)}ê°œ")
        print(f"   ğŸ“‹ ë†’ì€ ìƒê´€ê´€ê³„ ìŒ: {len(high_corr_pairs)}ê°œ")
        
        return final_features, analysis_result
    
    def get_feature_importance_summary(self, analysis_result: Dict[str, Any]) -> pd.DataFrame:
        """ë³€ìˆ˜ ì„ íƒ ê³¼ì • ìš”ì•½ ì •ë³´ ìƒì„±"""
        
        selection_summary = []
        
        # ì„ íƒëœ ë³€ìˆ˜ë“¤ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜
        for feature in analysis_result['final_features']:
            category = self._classify_feature(feature)
            
            selection_summary.append({
                'feature_name': feature,
                'category': category,
                'selection_reason': 'passed_correlation_filter',
                'domain_priority': self._get_domain_priority(feature),
                'is_original_weather': feature in self.domain_priorities['weather_original'],
                'is_derived': self._is_derived_feature(feature)
            })
        
        return pd.DataFrame(selection_summary)
    
    def _log_selection(self, kept_var: str, removed_var: str, 
                      correlation: float, reason: str):
        """ë³€ìˆ˜ ì„ íƒ ê³¼ì • ë¡œê¹…"""
        self.selection_log.append({
            'kept_variable': kept_var,
            'removed_variable': removed_var,
            'correlation': correlation,
            'selection_reason': reason,
            'timestamp': pd.Timestamp.now()
        })
    
    def _classify_feature(self, feature: str) -> str:
        """ë³€ìˆ˜ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        for category, variables in self.domain_priorities.items():
            if feature in variables:
                return category
        
        # íŒ¨í„´ ê¸°ë°˜ ë¶„ë¥˜
        if any(pattern in feature.lower() for pattern in ['interaction', 'poly']):
            return 'interaction_features'
        elif any(pattern in feature.lower() for pattern in ['roll', 'lag']):
            return 'temporal_features'
        elif any(pattern in feature.lower() for pattern in ['cluster', 'network']):
            return 'spatial_features'
        elif feature.startswith('pca_'):
            return 'pca_features'
        else:
            return 'other_features'
    
    def _get_domain_priority(self, feature: str) -> int:
        """ë³€ìˆ˜ì˜ ë„ë©”ì¸ ìš°ì„ ìˆœìœ„ ë°˜í™˜ (1=ìµœê³ )"""
        priority_order = [
            'weather_original', 'target', 'temporal_basic', 
            'derived_important', 'population', 'location'
        ]
        
        for i, category in enumerate(priority_order):
            if feature in self.domain_priorities.get(category, []):
                return i + 1
        
        return 10  # ê¸°íƒ€
    
    def _is_derived_feature(self, feature: str) -> bool:
        """íŒŒìƒ ë³€ìˆ˜ ì—¬ë¶€ í™•ì¸"""
        derived_patterns = [
            'avg', 'range', 'interaction', 'poly', 'roll', 'lag', 
            'cluster', 'network', 'pca_', 'sin', 'cos'
        ]
        return any(pattern in feature.lower() for pattern in derived_patterns)
    
    def save_analysis_results(self, analysis_result: Dict[str, Any], 
                            output_prefix: str = "smart_selection"):
        """ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        
        # 1. ë†’ì€ ìƒê´€ê´€ê³„ ìŒ
        if analysis_result['high_corr_pairs']:
            corr_df = pd.DataFrame(analysis_result['high_corr_pairs'])
            corr_df = corr_df.sort_values('correlation', ascending=False)
            corr_df.to_csv(f'{output_prefix}_high_correlations.csv', 
                          index=False, encoding='utf-8')
        
        # 2. ì œê±°ëœ ë³€ìˆ˜ ìƒì„¸ ì •ë³´
        if self.selection_log:
            selection_df = pd.DataFrame(self.selection_log)
            selection_df.to_csv(f'{output_prefix}_selection_log.csv', 
                               index=False, encoding='utf-8')
        
        # 3. ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ ìš”ì•½
        feature_summary = self.get_feature_importance_summary(analysis_result)
        feature_summary.to_csv(f'{output_prefix}_final_features.csv', 
                              index=False, encoding='utf-8')
        
        # 4. ìƒê´€ê´€ê³„ í–‰ë ¬
        analysis_result['corr_matrix'].to_csv(f'{output_prefix}_correlation_matrix.csv', 
                                             encoding='utf-8')
        
        print(f"\nğŸ’¾ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼ ì €ì¥:")
        print(f"   - {output_prefix}_high_correlations.csv")
        print(f"   - {output_prefix}_selection_log.csv")  
        print(f"   - {output_prefix}_final_features.csv")
        print(f"   - {output_prefix}_correlation_matrix.csv")
        
        return feature_summary
    
    def validate_selection(self, train_df: pd.DataFrame, test_df: pd.DataFrame,
                          final_features: List[str], target_col: str = 'call_count') -> Dict[str, float]:
        """ì„ íƒëœ ë³€ìˆ˜ë“¤ë¡œ ê°„ë‹¨í•œ ì„±ëŠ¥ ê²€ì¦"""
        
        from sklearn.ensemble import RandomForestRegressor
        from lightgbm import LGBMRegressor
        
        X_train = train_df[final_features].fillna(0)
        X_test = test_df[final_features].fillna(0)
        y_train = train_df[target_col]
        y_test = test_df[target_col]
        
        results = {}
        
        # RandomForestë¡œ ê°„ë‹¨ ê²€ì¦
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        rf_model.fit(X_train, y_train)
        rf_pred = rf_model.predict(X_test)
        
        results['RandomForest'] = {
            'RMSE': np.sqrt(mean_squared_error(y_test, rf_pred)),
            'R2': r2_score(y_test, rf_pred)
        }
        
        # LightGBMìœ¼ë¡œ ê°„ë‹¨ ê²€ì¦
        lgbm_model = LGBMRegressor(n_estimators=100, random_state=42, verbose=-1)
        lgbm_model.fit(X_train, y_train)
        lgbm_pred = lgbm_model.predict(X_test)
        
        results['LightGBM'] = {
            'RMSE': np.sqrt(mean_squared_error(y_test, lgbm_pred)),
            'R2': r2_score(y_test, lgbm_pred)
        }
        
        print(f"\nğŸ¯ ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ ì„ íƒ ë³€ìˆ˜ ì„±ëŠ¥ ê²€ì¦:")
        print(f"   RF:  RMSE {results['RandomForest']['RMSE']:.4f}, RÂ² {results['RandomForest']['R2']:.4f}")
        print(f"   LGBM: RMSE {results['LightGBM']['RMSE']:.4f}, RÂ² {results['LightGBM']['R2']:.4f}")
        
        return results 