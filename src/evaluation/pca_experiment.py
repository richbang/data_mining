"""PCA effect comparison experiment module for team discussion support."""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from lightgbm import LGBMRegressor
from typing import Dict, List, Any
import warnings
warnings.filterwarnings('ignore')

# ê¸°ì¡´ PCAHolder ì‚¬ìš© (ì¤‘ë³µ ë°©ì§€)
from src.features.pca_holder import PCAHolder


class PCAExperiment:
    """
    PCA ì‚¬ìš©/ë¯¸ì‚¬ìš© íš¨ê³¼ë¥¼ ë¹„êµí•˜ëŠ” ì‹¤í—˜ í´ë˜ìŠ¤.

    **ì‹¤í—˜ ë‚´ìš©:**
    - PCA ë¯¸ì‚¬ìš© vs ì‚¬ìš© ì„±ëŠ¥ ë¹„êµ
    - ë³€ìˆ˜ ê°œìˆ˜ ë³€í™” ë¶„ì„
    - ëª¨ë¸ë³„ íš¨ê³¼ ì°¨ì´ í™•ì¸
    """
    
    def __init__(self):
        self.results = {}
        self.recommendation = ""
    
    def compare_with_without_pca(self, train_feat: pd.DataFrame, test_feat: pd.DataFrame, 
                                final_features: List[str]) -> Dict[str, Any]:
        """PCA ì‚¬ìš©/ë¯¸ì‚¬ìš© ì„±ëŠ¥ ë¹„êµ ì‹¤í—˜"""
        print("\n" + "="*60)
        print("ğŸ”¬ PCA íš¨ê³¼ ë¶„ì„ ì‹¤í—˜ (íŒ€ì› ìš”ì²­ì‚¬í•­)")
        print("="*60)
        
        results = {}
        
        # PCA ì ìš©í•  ê¸°ìƒ ë³€ìˆ˜ë“¤
        pca_features = ['ta_max', 'ta_min', 'hm_max', 'hm_min', 'ws_max', 'rn_day']
        available_pca_features = [f for f in pca_features if f in train_feat.columns]
        
        if len(available_pca_features) < 3:
            print("âŒ PCA ì ìš© ê°€ëŠ¥í•œ ê¸°ìƒ ë³€ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ“Š PCA ì ìš© ëŒ€ìƒ: {available_pca_features}")
        
        # 1. PCA ì—†ëŠ” ë²„ì „
        print("\n1ï¸âƒ£ PCA ë¯¸ì‚¬ìš© ë²„ì „")
        results['without_pca'] = self._run_models_without_pca(
            train_feat, test_feat, final_features
        )
        
        # 2. PCA ìˆëŠ” ë²„ì „  
        print("\n2ï¸âƒ£ PCA ì‚¬ìš© ë²„ì „")
        results['with_pca'] = self._run_models_with_pca(
            train_feat, test_feat, final_features, available_pca_features
        )
        
        # 3. ê²°ê³¼ ë¹„êµ
        self._compare_results(results)
        
        # 4. ê²°ê³¼ ì €ì¥
        self._save_comparison_results(results)
        
        return results
    
    def _run_models_without_pca(self, train_feat: pd.DataFrame, test_feat: pd.DataFrame, 
                               final_features: List[str]) -> Dict[str, Any]:
        """PCA ì—†ì´ ëª¨ë¸ ì‹¤í–‰"""
        # PCA ë³€ìˆ˜ë“¤ ì œê±°
        features_no_pca = [f for f in final_features if not f.startswith('pca_')]
        
        X_train = train_feat[features_no_pca].copy()
        X_test = test_feat[features_no_pca].copy()
        y_train = train_feat['call_count'].copy()
        y_test = test_feat['call_count'].copy()
        
        # ì•ˆì „í•œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        X_train = X_train.fillna(X_train.mean())
        X_test = X_test.fillna(X_train.mean())  # trainì˜ í‰ê·  ì‚¬ìš©
        
        print(f"   ğŸ“‹ ë³€ìˆ˜ ê°œìˆ˜: {len(features_no_pca)}ê°œ")
        
        results = {}
        
        # LightGBM
        lgbm_model = LGBMRegressor(n_estimators=200, random_state=42, verbose=-1)
        lgbm_model.fit(X_train, y_train)
        lgbm_pred = lgbm_model.predict(X_test)
        
        results['LightGBM'] = {
            'RMSE': np.sqrt(mean_squared_error(y_test, lgbm_pred)),
            'R2': r2_score(y_test, lgbm_pred),
            'feature_count': len(features_no_pca)
        }
        
        # RandomForest
        rf_model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
        rf_model.fit(X_train, y_train)
        rf_pred = rf_model.predict(X_test)
        
        results['RandomForest'] = {
            'RMSE': np.sqrt(mean_squared_error(y_test, rf_pred)),
            'R2': r2_score(y_test, rf_pred),
            'feature_count': len(features_no_pca)
        }
        
        print(f"   âœ… LightGBM - RMSE: {results['LightGBM']['RMSE']:.4f}, RÂ²: {results['LightGBM']['R2']:.4f}")
        print(f"   âœ… RandomForest - RMSE: {results['RandomForest']['RMSE']:.4f}, RÂ²: {results['RandomForest']['R2']:.4f}")
        
        return results
    
    def _run_models_with_pca(self, train_feat: pd.DataFrame, test_feat: pd.DataFrame, 
                            final_features: List[str], pca_features: List[str]) -> Dict[str, Any]:
        """PCA í¬í•¨í•˜ì—¬ ëª¨ë¸ ì‹¤í–‰"""
        # PCA ì ìš© (ê¸°ì¡´ PCAHolder ë°©ì‹)
        pca_holder = PCAHolder(n_components=3)
        train_with_pca = train_feat.copy()
        test_with_pca = test_feat.copy()
        
        # ê¸°ì¡´ ë°©ì‹: fit í›„ transform
        pca_holder.fit(train_with_pca, pca_features)
        train_with_pca = pca_holder.transform(train_with_pca)
        test_with_pca = pca_holder.transform(test_with_pca)
        
        # PCA ë³€ìˆ˜ ì¶”ê°€ëœ í”¼ì²˜ ë¦¬ìŠ¤íŠ¸
        pca_columns = ['pca_1', 'pca_2', 'pca_3']
        features_with_pca = final_features + pca_columns
        
        # PCA ë³€ìˆ˜ê°€ ì´ë¯¸ í¬í•¨ëœ ê²½ìš° ì¤‘ë³µ ì œê±°
        features_with_pca = list(set(features_with_pca))
        
        X_train = train_with_pca[features_with_pca].copy()
        X_test = test_with_pca[features_with_pca].copy()
        y_train = train_with_pca['call_count'].copy()
        y_test = test_with_pca['call_count'].copy()
        
        # ì•ˆì „í•œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        X_train = X_train.fillna(X_train.mean())
        X_test = X_test.fillna(X_train.mean())  # trainì˜ í‰ê·  ì‚¬ìš©
        
        print(f"   ğŸ“‹ ë³€ìˆ˜ ê°œìˆ˜: {len(features_with_pca)}ê°œ (PCA +3ê°œ)")
        
        results = {}
        
        # LightGBM
        lgbm_model = LGBMRegressor(n_estimators=200, random_state=42, verbose=-1)
        lgbm_model.fit(X_train, y_train)
        lgbm_pred = lgbm_model.predict(X_test)
        
        results['LightGBM'] = {
            'RMSE': np.sqrt(mean_squared_error(y_test, lgbm_pred)),
            'R2': r2_score(y_test, lgbm_pred),
            'feature_count': len(features_with_pca)
        }
        
        # RandomForest
        rf_model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
        rf_model.fit(X_train, y_train)
        rf_pred = rf_model.predict(X_test)
        
        results['RandomForest'] = {
            'RMSE': np.sqrt(mean_squared_error(y_test, rf_pred)),
            'R2': r2_score(y_test, rf_pred),
            'feature_count': len(features_with_pca)
        }
        
        print(f"   âœ… LightGBM - RMSE: {results['LightGBM']['RMSE']:.4f}, RÂ²: {results['LightGBM']['R2']:.4f}")
        print(f"   âœ… RandomForest - RMSE: {results['RandomForest']['RMSE']:.4f}, RÂ²: {results['RandomForest']['R2']:.4f}")
        
        return results
    
    def _compare_results(self, results: Dict[str, Any]):
        """ê²°ê³¼ ë¹„êµ ë¶„ì„"""
        print("\n" + "="*60)
        print("ğŸ“ˆ PCA íš¨ê³¼ ë¶„ì„ ê²°ê³¼")
        print("="*60)
        
        comparison_df = []
        
        for model in ['LightGBM', 'RandomForest']:
            without_pca = results['without_pca'][model]
            with_pca = results['with_pca'][model]
            
            rmse_diff = with_pca['RMSE'] - without_pca['RMSE']
            r2_diff = with_pca['R2'] - without_pca['R2']
            
            comparison_df.append({
                'Model': model,
                'RMSE_without_PCA': without_pca['RMSE'],
                'RMSE_with_PCA': with_pca['RMSE'],
                'RMSE_ì°¨ì´': rmse_diff,
                'RMSE_ê°œì„ ìœ¨(%)': -rmse_diff/without_pca['RMSE']*100,
                'R2_without_PCA': without_pca['R2'],
                'R2_with_PCA': with_pca['R2'],
                'R2_ì°¨ì´': r2_diff,
                'Variables_without_PCA': without_pca['feature_count'],
                'Variables_with_PCA': with_pca['feature_count']
            })
        
        comp_df = pd.DataFrame(comparison_df)
        print(comp_df.round(4))
        
        # ê¶Œì¥ì‚¬í•­ ì¶œë ¥
        print("\nğŸ¯ **íŒ€ì› ë…¼ì˜ ì‚¬í•­ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼**")
        
        lgbm_improved = comp_df.loc[0, 'RMSE_ê°œì„ ìœ¨(%)'] > 0
        rf_improved = comp_df.loc[1, 'RMSE_ê°œì„ ìœ¨(%)'] > 0
        
        if lgbm_improved and rf_improved:
            print("âœ… **PCA ì‚¬ìš© ê¶Œì¥**: ë‘ ëª¨ë¸ ëª¨ë‘ ì„±ëŠ¥ í–¥ìƒ")
            recommendation = "PCA ì‚¬ìš©"
        elif lgbm_improved or rf_improved:
            print("âš ï¸ **í˜¼ì¬ëœ ê²°ê³¼**: í•œ ëª¨ë¸ë§Œ ì„±ëŠ¥ í–¥ìƒ")
            recommendation = "ëª¨ë¸ë³„ ì„ íƒì  ì‚¬ìš©"
        else:
            print("âŒ **PCA ë¯¸ì‚¬ìš© ê¶Œì¥**: ë‘ ëª¨ë¸ ëª¨ë‘ ì„±ëŠ¥ ì €í•˜")
            print("   ğŸ” ì–‘ë‹¤í˜„ íŒ€ì› ì˜ê²¬ ì§€ì§€: 'ë³€ìˆ˜ê°€ ë§ìœ¼ë‹ˆ PCA ë³€ìˆ˜ê¹Œì§€ ì¶”ê°€ ì•ˆ í•´ë„ ê´œì°®ë‹¤'")
            recommendation = "PCA ë¯¸ì‚¬ìš©"
        
        # ë³€ìˆ˜ ê°œìˆ˜ ê´€ì ì—ì„œ ë¶„ì„
        var_increase = comp_df.loc[0, 'Variables_with_PCA'] - comp_df.loc[0, 'Variables_without_PCA']
        print(f"\nğŸ“Š **ë³€ìˆ˜ ê°œìˆ˜ ë¶„ì„**")
        print(f"   â€¢ PCA ë¯¸ì‚¬ìš©: {comp_df.loc[0, 'Variables_without_PCA']}ê°œ ë³€ìˆ˜")
        print(f"   â€¢ PCA ì‚¬ìš©: {comp_df.loc[0, 'Variables_with_PCA']}ê°œ ë³€ìˆ˜ (+{var_increase}ê°œ)")
        
        self.recommendation = recommendation
        
    def _save_comparison_results(self, results: Dict[str, Any]):
        """ë¹„êµ ê²°ê³¼ ì €ì¥"""
        # ìƒì„¸ ê²°ê³¼ ì €ì¥
        detailed_results = []
        for pca_status in ['without_pca', 'with_pca']:
            for model in ['LightGBM', 'RandomForest']:
                result = results[pca_status][model]
                detailed_results.append({
                    'PCA_Status': pca_status,
                    'Model': model,
                    'RMSE': result['RMSE'],
                    'R2': result['R2'],
                    'Feature_Count': result['feature_count']
                })
        
        detailed_df = pd.DataFrame(detailed_results)
        detailed_df.to_csv('pca_comparison_detailed.csv', index=False, encoding='utf-8')
        
        # ìš”ì•½ ê²°ê³¼ ì €ì¥
        summary = {
            'Recommendation': self.recommendation,
            'Analysis_Date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
        }
        
        pd.DataFrame([summary]).to_csv('pca_analysis_summary.csv', index=False, encoding='utf-8')
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
        print(f"   â€¢ pca_comparison_detailed.csv")
        print(f"   â€¢ pca_analysis_summary.csv")
        print(f"   â€¢ ìµœì¢… ê¶Œì¥ì‚¬í•­: {self.recommendation}")
    
    def get_recommendation(self) -> str:
        """íŒ€ ë…¼ì˜ë¥¼ ìœ„í•œ ìµœì¢… ê¶Œì¥ì‚¬í•­ ë°˜í™˜"""
        return self.recommendation 