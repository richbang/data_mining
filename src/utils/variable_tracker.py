"""
ë³€ìˆ˜ ì„ íƒ ì¶”ì  ëª¨ë“ˆ - íˆ¬ëª…í•œ í”¼ì²˜ ì„ íƒ ê³¼ì • ê¸°ë¡

ê°œë°œ ë°°ê²½:
- ìŠ¹ì •ë‹˜ì´ "ì–´ë–¤ ë³€ìˆ˜ê°€ ì™œ ì œê±°ë˜ì—ˆëŠ”ì§€ ëª¨ë¥´ê² ë‹¤"ê³  ì§€ì 
- íŒ€ì›ë“¤ì´ í”¼ì²˜ ì„ íƒ ê³¼ì •ì˜ íˆ¬ëª…ì„±ì„ ìš”êµ¬
- ëª¨ë“  ë‹¨ê³„ë¥¼ ìƒì„¸ížˆ ê¸°ë¡í•´ì„œ ë‚˜ì¤‘ì— ê²€í†  ê°€ëŠ¥í•˜ë„ë¡ êµ¬í˜„
- ê° ëª¨ë¸ë³„ ë³€ìˆ˜ ì¤‘ìš”ë„ë„ ë¹„êµ ë¶„ì„ ê°€ëŠ¥

ê²°ê³¼:
- ëª¨ë“  ê²°ì • ê³¼ì •ì„ CSVë¡œ ì €ìž¥í•´ì„œ ì—‘ì…€ì—ì„œë„ í™•ì¸ ê°€ëŠ¥
"""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score
from typing import Dict, List, Any


class VariableTracker:
    """
    ë³€ìˆ˜ ì„ íƒ ê³¼ì • íˆ¬ëª…ì„± í™•ë³´ë¥¼ ìœ„í•œ ì¶”ì  ì‹œìŠ¤í…œ
    
    **ì €ìž¥ë˜ëŠ” íŒŒì¼ë“¤:**
    1. variables_*_all.csv: ê° ë‹¨ê³„ë³„ ì „ì²´ ë³€ìˆ˜ ëª©ë¡
    2. correlation_matrix_full.csv: ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬
    3. high_correlation_pairs.csv: ë†’ì€ ìƒê´€ê´€ê³„ ë³€ìˆ˜ ìŒ
    4. removed_variables_correlation.csv: ì œê±°ëœ ë³€ìˆ˜ì™€ ì‚¬ìœ 
    5. feature_importance_*.csv: ëª¨ë¸ë³„ ë³€ìˆ˜ ì¤‘ìš”ë„
    6. comprehensive_feature_analysis.csv: ì¢…í•© ë³€ìˆ˜ ë¶„ì„
    7. variable_selection_summary.csv: ì „ì²´ ìš”ì•½
    """
    
    def __init__(self):
        """
        ë³€ìˆ˜ ì¶”ì ê¸° ì´ˆê¸°í™”
        
        ê° ë‹¨ê³„ë³„ ì •ë³´ë¥¼ ë‹´ì„ ë”•ì…”ë„ˆë¦¬ë“¤ ì¤€ë¹„
        - ë‚˜ì¤‘ì— ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•´ì„œ ë¦¬í¬íŠ¸ ìƒì„±
        """
        self.initial_variables = {}      # ê° ë‹¨ê³„ë³„ ì´ˆê¸° ë³€ìˆ˜ ëª©ë¡
        self.correlation_analysis = {}   # ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼
        self.removed_variables = {}      # ì œê±°ëœ ë³€ìˆ˜ì™€ ì‚¬ìœ 
        self.final_variables = {}        # ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ë“¤
        self.model_importance = {}       # ëª¨ë¸ë³„ ë³€ìˆ˜ ì¤‘ìš”ë„
        self.selection_summary = {}      # ì „ì²´ ìš”ì•½ ì •ë³´
    
    def save_initial_variables(self, df: pd.DataFrame, stage: str = "initial"):
        """
        ê° ë‹¨ê³„ë³„ ìƒì„±ëœ ëª¨ë“  ë³€ìˆ˜ ëª©ë¡ ì €ìž¥
        
        íŒ€ì›ë“¤ì´ "í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í›„ ë³€ìˆ˜ê°€ ëª‡ ê°œë‚˜ ëëŠ”ì§€" ê¶ê¸ˆí•´í•´ì„œ
        ê° ë‹¨ê³„ë³„ë¡œ ìƒì„¸í•˜ê²Œ ê¸°ë¡í•˜ë„ë¡ êµ¬í˜„
        
        ì €ìž¥ ì •ë³´:
        - ì „ì²´ ë³€ìˆ˜ ëª©ë¡ ë° íƒ€ìž…
        - ê²°ì¸¡ì¹˜ ì •ë³´
        - ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ë¶„ë¥˜
        """
        all_cols = df.columns.tolist()
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        self.initial_variables[stage] = {
            'stage': stage,
            'all_columns': all_cols,
            'numeric_columns': numeric_cols,
            'total_count': len(all_cols),
            'numeric_count': len(numeric_cols),
            'categorical_columns': [col for col in all_cols if col not in numeric_cols],
            'timestamp': pd.Timestamp.now()
        }
        
        # outputs í´ë”ì— CSV ì €ìž¥
        import os
        os.makedirs('outputs', exist_ok=True)
        
        pd.DataFrame({
            'variable_name': all_cols,
            'data_type': [str(df[col].dtype) for col in all_cols],
            'is_numeric': [col in numeric_cols for col in all_cols],
            'null_count': [df[col].isnull().sum() for col in all_cols],
            'null_percentage': [df[col].isnull().sum() / len(df) * 100 for col in all_cols]
        }).to_csv(f'outputs/variables_{stage}_all.csv', index=False, encoding='utf-8')
        
        print(f"âœ… {stage} ë‹¨ê³„ ë³€ìˆ˜ ëª©ë¡ ì €ìž¥: outputs/variables_{stage}_all.csv")
        print(f"   ì´ {len(all_cols)}ê°œ ë³€ìˆ˜ (ìˆ˜ì¹˜í˜•: {len(numeric_cols)}ê°œ)")
        
    def save_correlation_analysis(self, corr_matrix: pd.DataFrame, threshold: float, 
                                removed_vars: List[str], kept_vars: List[str]):
        """ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ì €ìž¥"""
        
        # outputs í´ë” ìƒì„±
        import os
        os.makedirs('outputs', exist_ok=True)
        
        # 1. ìƒê´€ê´€ê³„ í–‰ë ¬ ì €ìž¥
        corr_matrix.to_csv('outputs/correlation_matrix_full.csv', encoding='utf-8')
        
        # 2. ë†’ì€ ìƒê´€ê´€ê³„ ë³€ìˆ˜ ìŒ ì°¾ê¸° ë° ì €ìž¥
        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        high_corr_pairs = []
        
        for i in range(len(upper.columns)):
            for j in range(len(upper.columns)):
                if pd.notna(upper.iloc[i, j]) and upper.iloc[i, j] > threshold:
                    high_corr_pairs.append({
                        'variable_1': upper.columns[i],
                        'variable_2': upper.columns[j],
                        'correlation': upper.iloc[i, j],
                        'above_threshold': True,
                        'threshold_used': threshold
                    })
        
        if high_corr_pairs:
            high_corr_df = pd.DataFrame(high_corr_pairs)
            high_corr_df = high_corr_df.sort_values('correlation', ascending=False)
            high_corr_df.to_csv('outputs/high_correlation_pairs.csv', index=False, encoding='utf-8')
        
        # 3. ì œê±°ëœ ë³€ìˆ˜ì™€ ì‚¬ìœ  ì €ìž¥
        removal_reasons = []
        for var in removed_vars:
            if high_corr_pairs:  # high_corr_pairsê°€ ë¹„ì–´ìžˆì§€ ì•Šì„ ë•Œë§Œ
                # í•´ë‹¹ ë³€ìˆ˜ê°€ ì œê±°ëœ ì´ìœ  ì°¾ê¸°
                related_pairs = [p for p in high_corr_pairs 
                               if p['variable_1'] == var or p['variable_2'] == var]
                
                if related_pairs:
                    max_corr_pair = max(related_pairs, key=lambda x: x['correlation'])
                    other_var = (max_corr_pair['variable_2'] if max_corr_pair['variable_1'] == var 
                               else max_corr_pair['variable_1'])
                    removal_reasons.append({
                        'removed_variable': var,
                        'reason': 'high_correlation',
                        'correlation_with': other_var,
                        'correlation_value': max_corr_pair['correlation'],
                        'kept_variable': other_var if other_var in kept_vars else 'unknown',
                        'threshold': threshold
                    })
        
        if removal_reasons:
            pd.DataFrame(removal_reasons).to_csv('outputs/removed_variables_correlation.csv', index=False, encoding='utf-8')
        
        # 4. ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ ì €ìž¥
        pd.DataFrame({
            'selected_variable': kept_vars,
            'selection_stage': 'after_correlation_filtering',
            'selection_reason': 'passed_correlation_threshold'
        }).to_csv('outputs/selected_variables_after_correlation.csv', index=False, encoding='utf-8')
        
        self.correlation_analysis = {
            'threshold': threshold,
            'total_pairs_above_threshold': len(high_corr_pairs) if high_corr_pairs else 0,
            'removed_count': len(removed_vars),
            'kept_count': len(kept_vars),
            'high_corr_pairs': high_corr_pairs
        }
        
        print(f"âœ… ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ")
        print(f"   - ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬: outputs/correlation_matrix_full.csv")
        print(f"   - ë†’ì€ ìƒê´€ê´€ê³„ ìŒ: outputs/high_correlation_pairs.csv ({len(high_corr_pairs) if high_corr_pairs else 0}ê°œ)")
        print(f"   - ì œê±°ëœ ë³€ìˆ˜: outputs/removed_variables_correlation.csv ({len(removed_vars)}ê°œ)")
        print(f"   - ì„ íƒëœ ë³€ìˆ˜: outputs/selected_variables_after_correlation.csv ({len(kept_vars)}ê°œ)")
    
    def save_model_importance(self, model_name: str, model: Any, feature_names: List[str], 
                            X_test: pd.DataFrame, y_test: pd.Series, predictions: np.ndarray):
        """ëª¨ë¸ë³„ ë³€ìˆ˜ ì¤‘ìš”ë„ì™€ ì„±ëŠ¥ ì €ìž¥"""
        
        # 1. ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ
        rmse = np.sqrt(mean_squared_error(y_test, predictions))
        r2 = r2_score(y_test, predictions)
        mae = np.mean(np.abs(y_test - predictions))
        
        # 2. Feature Importance ì¶”ì¶œ
        if hasattr(model, 'feature_importances_'):
            importance_values = model.feature_importances_
        elif hasattr(model, 'coef_'):
            importance_values = np.abs(model.coef_)
        else:
            importance_values = np.zeros(len(feature_names))
        
        # 3. ë³€ìˆ˜ë³„ ìƒì„¸ ì •ë³´ ìƒì„±
        feature_analysis = []
        for i, (feature, importance) in enumerate(zip(feature_names, importance_values)):
            feature_analysis.append({
                'model_name': model_name,
                'feature_name': feature,
                'importance_score': importance,
                'importance_rank': i + 1,
                'importance_percentage': importance / importance_values.sum() * 100 if importance_values.sum() > 0 else 0,
                'cumulative_importance': importance_values[:i+1].sum() / importance_values.sum() * 100 if importance_values.sum() > 0 else 0,
                'is_top_10': i < 10,
                'is_top_20': i < 20
            })
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        feature_analysis = sorted(feature_analysis, key=lambda x: x['importance_score'], reverse=True)
        
        # ìˆœìœ„ ìž¬ì¡°ì •
        for i, item in enumerate(feature_analysis):
            item['importance_rank'] = i + 1
            item['cumulative_importance'] = sum([x['importance_score'] for x in feature_analysis[:i+1]]) / sum([x['importance_score'] for x in feature_analysis]) * 100
        
        # 4. outputs í´ë”ì— ì €ìž¥
        import os
        os.makedirs('outputs', exist_ok=True)
        
        feature_df = pd.DataFrame(feature_analysis)
        feature_df.to_csv(f'outputs/feature_importance_{model_name.lower()}.csv', index=False, encoding='utf-8')
        
        # 5. ëª¨ë¸ ì„±ëŠ¥ ì €ìž¥
        performance = {
            'model_name': model_name,
            'rmse': rmse,
            'r2_score': r2,
            'mae': mae,
            'n_features': len(feature_names),
            'n_samples': len(y_test),
            'top_feature': feature_analysis[0]['feature_name'] if feature_analysis else 'none',
            'top_importance': feature_analysis[0]['importance_score'] if feature_analysis else 0
        }
        
        self.model_importance[model_name] = {
            'performance': performance,
            'feature_importance': feature_analysis
        }
        
        print(f"âœ… {model_name} ëª¨ë¸ ë¶„ì„ ì €ìž¥: outputs/feature_importance_{model_name.lower()}.csv")
        print(f"   RMSE: {rmse:.4f}, RÂ²: {r2:.4f}, Top feature: {performance['top_feature']}")
        
        return feature_df
    
    def save_comprehensive_summary(self):
        """ì „ì²´ ë³€ìˆ˜ ì„ íƒ ê³¼ì • ì¢…í•© ìš”ì•½ ì €ìž¥"""
        
        # outputs í´ë” ìƒì„±
        import os
        os.makedirs('outputs', exist_ok=True)
        
        # 1. ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        model_comparison = []
        for model_name, info in self.model_importance.items():
            model_comparison.append(info['performance'])
        
        if model_comparison:
            pd.DataFrame(model_comparison).to_csv('outputs/model_performance_comparison.csv', index=False, encoding='utf-8')
        
        # 2. ë³€ìˆ˜ë³„ ì¢…í•© ì¤‘ìš”ë„ (ëª¨ë“  ëª¨ë¸ í‰ê· )
        all_features = set()
        for model_name, info in self.model_importance.items():
            for feat_info in info['feature_importance']:
                all_features.add(feat_info['feature_name'])
        
        comprehensive_features = []
        for feature in all_features:
            feature_scores = []
            feature_ranks = []
            appeared_models = []
            
            for model_name, info in self.model_importance.items():
                for feat_info in info['feature_importance']:
                    if feat_info['feature_name'] == feature:
                        feature_scores.append(feat_info['importance_score'])
                        feature_ranks.append(feat_info['importance_rank'])
                        appeared_models.append(model_name)
                        break
            
            if feature_scores:
                comprehensive_features.append({
                    'feature_name': feature,
                    'avg_importance': np.mean(feature_scores),
                    'std_importance': np.std(feature_scores),
                    'avg_rank': np.mean(feature_ranks),
                    'std_rank': np.std(feature_ranks),
                    'appeared_in_models': len(appeared_models),
                    'model_list': ', '.join(appeared_models),
                    'max_importance': np.max(feature_scores),
                    'min_importance': np.min(feature_scores),
                    'is_consistent_top10': all(rank <= 10 for rank in feature_ranks),
                    'is_consistent_top20': all(rank <= 20 for rank in feature_ranks)
                })
        
        # í‰ê·  ì¤‘ìš”ë„ë¡œ ì •ë ¬
        comprehensive_features = sorted(comprehensive_features, key=lambda x: x['avg_importance'], reverse=True)
        
        if comprehensive_features:
            pd.DataFrame(comprehensive_features).to_csv('outputs/comprehensive_feature_analysis.csv', index=False, encoding='utf-8')
        
        # 3. ì „ì²´ ìš”ì•½ í†µê³„
        initial_count = 0
        for stage, info in self.initial_variables.items():
            if stage == "after_feature_engineering":
                initial_count = info.get('numeric_count', 0)
                break
        
        summary_stats = {
            'total_initial_variables': initial_count,
            'total_numeric_variables': initial_count,
            'variables_removed_by_correlation': self.correlation_analysis.get('removed_count', 0),
            'final_variables_count': len(all_features),
            'correlation_threshold_used': self.correlation_analysis.get('threshold', 'unknown'),
            'best_model': max(model_comparison, key=lambda x: x['r2_score'])['model_name'] if model_comparison else 'unknown',
            'best_rmse': min(model_comparison, key=lambda x: x['rmse'])['rmse'] if model_comparison else 'unknown',
            'best_r2': max(model_comparison, key=lambda x: x['r2_score'])['r2_score'] if model_comparison else 'unknown'
        }
        
        pd.DataFrame([summary_stats]).to_csv('outputs/variable_selection_summary.csv', index=False, encoding='utf-8')
        
        print(f"\nðŸŽ¯ ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ:")
        print(f"   - ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: outputs/model_performance_comparison.csv")
        print(f"   - ì¢…í•© ë³€ìˆ˜ ë¶„ì„: outputs/comprehensive_feature_analysis.csv") 
        print(f"   - ì „ì²´ ìš”ì•½: outputs/variable_selection_summary.csv")
        print(f"   - ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {summary_stats['best_model']} (RÂ²: {summary_stats['best_r2']:.3f})") 