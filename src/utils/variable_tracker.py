"""Variable selection tracking module for transparent feature selection process."""

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, r2_score
from typing import Dict, List, Any


class VariableTracker:
    """
    ë³€ìˆ˜ ì„ íƒ ê³¼ì •ì„ ì¶”ì í•˜ê³  ë¶„ì„í•˜ëŠ” í´ëž˜ìŠ¤.
    
    **ì£¼ìš” ê¸°ëŠ¥:**
    - ë‹¨ê³„ë³„ ë³€ìˆ˜ ëª©ë¡ ì €ìž¥
    - ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ì €ìž¥  
    - ëª¨ë¸ë³„ ë³€ìˆ˜ ì¤‘ìš”ë„ ì €ìž¥
    - ì¢…í•© ë¶„ì„ ê²°ê³¼ ìƒì„±
    """
    
    def __init__(self):
        self.initial_variables = {}
        self.correlation_analysis = {}
        self.removed_variables = {}
        self.final_variables = {}
        self.model_importance = {}
        self.selection_summary = {}
    
    def save_initial_variables(self, df: pd.DataFrame, stage: str = "initial"):
        """ì´ˆê¸° ìƒì„±ëœ ëª¨ë“  ë³€ìˆ˜ ì €ìž¥"""
        all_cols = df.columns.tolist()
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        self.initial_variables[stage] = {
            'stage': stage,
            'all_columns': all_cols,
            'numeric_columns': numeric_cols,
            'total_count': len(all_cols),
            'numeric_count': len(numeric_cols),
            'categorical_columns': [col for col in all_cols if col not in numeric_cols],
            'timestamp': pd.Timestamp.now()
        }
        
        # CSVë¡œ ì €ìž¥
        pd.DataFrame({
            'variable_name': all_cols,
            'data_type': [str(df[col].dtype) for col in all_cols],
            'is_numeric': [col in numeric_cols for col in all_cols],
            'null_count': [df[col].isnull().sum() for col in all_cols],
            'null_percentage': [df[col].isnull().sum() / len(df) * 100 for col in all_cols]
        }).to_csv(f'variables_{stage}_all.csv', index=False, encoding='utf-8')
        
        print(f"âœ… {stage} ë‹¨ê³„ ë³€ìˆ˜ ëª©ë¡ ì €ìž¥: variables_{stage}_all.csv")
        print(f"   ì´ {len(all_cols)}ê°œ ë³€ìˆ˜ (ìˆ˜ì¹˜í˜•: {len(numeric_cols)}ê°œ)")
        
    def save_correlation_analysis(self, corr_matrix: pd.DataFrame, threshold: float, 
                                removed_vars: List[str], kept_vars: List[str]):
        """ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ì €ìž¥"""
        
        # 1. ìƒê´€ê´€ê³„ í–‰ë ¬ ì €ìž¥
        corr_matrix.to_csv('correlation_matrix_full.csv', encoding='utf-8')
        
        # 2. ë†’ì€ ìƒê´€ê´€ê³„ ë³€ìˆ˜ ìŒ ì°¾ê¸° ë° ì €ìž¥
        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
        high_corr_pairs = []
        
        for i in range(len(upper.columns)):
            for j in range(len(upper.columns)):
                if pd.notna(upper.iloc[i, j]) and upper.iloc[i, j] > threshold:
                    high_corr_pairs.append({
                        'variable_1': upper.columns[i],
                        'variable_2': upper.columns[j],
                        'correlation': upper.iloc[i, j],
                        'above_threshold': True,
                        'threshold_used': threshold
                    })
        
        if high_corr_pairs:
            high_corr_df = pd.DataFrame(high_corr_pairs)
            high_corr_df = high_corr_df.sort_values('correlation', ascending=False)
            high_corr_df.to_csv('high_correlation_pairs.csv', index=False, encoding='utf-8')
        
        # 3. ì œê±°ëœ ë³€ìˆ˜ì™€ ì‚¬ìœ  ì €ìž¥
        removal_reasons = []
        for var in removed_vars:
            if high_corr_pairs:  # high_corr_pairsê°€ ë¹„ì–´ìžˆì§€ ì•Šì„ ë•Œë§Œ
                # í•´ë‹¹ ë³€ìˆ˜ê°€ ì œê±°ëœ ì´ìœ  ì°¾ê¸°
                related_pairs = [p for p in high_corr_pairs 
                               if p['variable_1'] == var or p['variable_2'] == var]
                
                if related_pairs:
                    max_corr_pair = max(related_pairs, key=lambda x: x['correlation'])
                    other_var = (max_corr_pair['variable_2'] if max_corr_pair['variable_1'] == var 
                               else max_corr_pair['variable_1'])
                    removal_reasons.append({
                        'removed_variable': var,
                        'reason': 'high_correlation',
                        'correlation_with': other_var,
                        'correlation_value': max_corr_pair['correlation'],
                        'kept_variable': other_var if other_var in kept_vars else 'unknown',
                        'threshold': threshold
                    })
        
        if removal_reasons:
            pd.DataFrame(removal_reasons).to_csv('removed_variables_correlation.csv', index=False, encoding='utf-8')
        
        # 4. ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ ì €ìž¥
        pd.DataFrame({
            'selected_variable': kept_vars,
            'selection_stage': 'after_correlation_filtering',
            'selection_reason': 'passed_correlation_threshold'
        }).to_csv('selected_variables_after_correlation.csv', index=False, encoding='utf-8')
        
        self.correlation_analysis = {
            'threshold': threshold,
            'total_pairs_above_threshold': len(high_corr_pairs) if high_corr_pairs else 0,
            'removed_count': len(removed_vars),
            'kept_count': len(kept_vars),
            'high_corr_pairs': high_corr_pairs
        }
        
        print(f"âœ… ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ")
        print(f"   - ì „ì²´ ìƒê´€ê´€ê³„ í–‰ë ¬: correlation_matrix_full.csv")
        print(f"   - ë†’ì€ ìƒê´€ê´€ê³„ ìŒ: high_correlation_pairs.csv ({len(high_corr_pairs) if high_corr_pairs else 0}ê°œ)")
        print(f"   - ì œê±°ëœ ë³€ìˆ˜: removed_variables_correlation.csv ({len(removed_vars)}ê°œ)")
        print(f"   - ì„ íƒëœ ë³€ìˆ˜: selected_variables_after_correlation.csv ({len(kept_vars)}ê°œ)")
    
    def save_model_importance(self, model_name: str, model: Any, feature_names: List[str], 
                            X_test: pd.DataFrame, y_test: pd.Series, predictions: np.ndarray):
        """ëª¨ë¸ë³„ ë³€ìˆ˜ ì¤‘ìš”ë„ì™€ ì„±ëŠ¥ ì €ìž¥"""
        
        # 1. ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ
        rmse = np.sqrt(mean_squared_error(y_test, predictions))
        r2 = r2_score(y_test, predictions)
        mae = np.mean(np.abs(y_test - predictions))
        
        # 2. Feature Importance ì¶”ì¶œ
        if hasattr(model, 'feature_importances_'):
            importance_values = model.feature_importances_
        elif hasattr(model, 'coef_'):
            importance_values = np.abs(model.coef_)
        else:
            importance_values = np.zeros(len(feature_names))
        
        # 3. ë³€ìˆ˜ë³„ ìƒì„¸ ì •ë³´ ìƒì„±
        feature_analysis = []
        for i, (feature, importance) in enumerate(zip(feature_names, importance_values)):
            feature_analysis.append({
                'model_name': model_name,
                'feature_name': feature,
                'importance_score': importance,
                'importance_rank': i + 1,
                'importance_percentage': importance / importance_values.sum() * 100 if importance_values.sum() > 0 else 0,
                'cumulative_importance': importance_values[:i+1].sum() / importance_values.sum() * 100 if importance_values.sum() > 0 else 0,
                'is_top_10': i < 10,
                'is_top_20': i < 20
            })
        
        # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        feature_analysis = sorted(feature_analysis, key=lambda x: x['importance_score'], reverse=True)
        
        # ìˆœìœ„ ìž¬ì¡°ì •
        for i, item in enumerate(feature_analysis):
            item['importance_rank'] = i + 1
            item['cumulative_importance'] = sum([x['importance_score'] for x in feature_analysis[:i+1]]) / sum([x['importance_score'] for x in feature_analysis]) * 100
        
        # 4. ì €ìž¥
        feature_df = pd.DataFrame(feature_analysis)
        feature_df.to_csv(f'feature_importance_{model_name.lower()}.csv', index=False, encoding='utf-8')
        
        # 5. ëª¨ë¸ ì„±ëŠ¥ ì €ìž¥
        performance = {
            'model_name': model_name,
            'rmse': rmse,
            'r2_score': r2,
            'mae': mae,
            'n_features': len(feature_names),
            'n_samples': len(y_test),
            'top_feature': feature_analysis[0]['feature_name'] if feature_analysis else 'none',
            'top_importance': feature_analysis[0]['importance_score'] if feature_analysis else 0
        }
        
        self.model_importance[model_name] = {
            'performance': performance,
            'feature_importance': feature_analysis
        }
        
        print(f"âœ… {model_name} ëª¨ë¸ ë¶„ì„ ì €ìž¥: feature_importance_{model_name.lower()}.csv")
        print(f"   RMSE: {rmse:.4f}, RÂ²: {r2:.4f}, Top feature: {performance['top_feature']}")
        
        return feature_df
    
    def save_comprehensive_summary(self):
        """ì „ì²´ ë³€ìˆ˜ ì„ íƒ ê³¼ì • ì¢…í•© ìš”ì•½ ì €ìž¥"""
        
        # 1. ëª¨ë“  ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
        model_comparison = []
        for model_name, info in self.model_importance.items():
            model_comparison.append(info['performance'])
        
        if model_comparison:
            pd.DataFrame(model_comparison).to_csv('model_performance_comparison.csv', index=False, encoding='utf-8')
        
        # 2. ë³€ìˆ˜ë³„ ì¢…í•© ì¤‘ìš”ë„ (ëª¨ë“  ëª¨ë¸ í‰ê· )
        all_features = set()
        for model_name, info in self.model_importance.items():
            for feat_info in info['feature_importance']:
                all_features.add(feat_info['feature_name'])
        
        comprehensive_features = []
        for feature in all_features:
            feature_scores = []
            feature_ranks = []
            appeared_models = []
            
            for model_name, info in self.model_importance.items():
                for feat_info in info['feature_importance']:
                    if feat_info['feature_name'] == feature:
                        feature_scores.append(feat_info['importance_score'])
                        feature_ranks.append(feat_info['importance_rank'])
                        appeared_models.append(model_name)
                        break
            
            if feature_scores:
                comprehensive_features.append({
                    'feature_name': feature,
                    'avg_importance': np.mean(feature_scores),
                    'std_importance': np.std(feature_scores),
                    'avg_rank': np.mean(feature_ranks),
                    'std_rank': np.std(feature_ranks),
                    'appeared_in_models': len(appeared_models),
                    'model_list': ', '.join(appeared_models),
                    'max_importance': np.max(feature_scores),
                    'min_importance': np.min(feature_scores),
                    'is_consistent_top10': all(rank <= 10 for rank in feature_ranks),
                    'is_consistent_top20': all(rank <= 20 for rank in feature_ranks)
                })
        
        # í‰ê·  ì¤‘ìš”ë„ë¡œ ì •ë ¬
        comprehensive_features = sorted(comprehensive_features, key=lambda x: x['avg_importance'], reverse=True)
        
        if comprehensive_features:
            pd.DataFrame(comprehensive_features).to_csv('comprehensive_feature_analysis.csv', index=False, encoding='utf-8')
        
        # 3. ì „ì²´ ìš”ì•½ í†µê³„
        initial_count = 0
        for stage, info in self.initial_variables.items():
            if stage == "after_feature_engineering":
                initial_count = info.get('numeric_count', 0)
                break
        
        summary_stats = {
            'total_initial_variables': initial_count,
            'total_numeric_variables': initial_count,
            'variables_removed_by_correlation': self.correlation_analysis.get('removed_count', 0),
            'final_variables_count': len(all_features),
            'correlation_threshold_used': self.correlation_analysis.get('threshold', 'unknown'),
            'best_model': max(model_comparison, key=lambda x: x['r2_score'])['model_name'] if model_comparison else 'unknown',
            'best_rmse': min(model_comparison, key=lambda x: x['rmse'])['rmse'] if model_comparison else 'unknown',
            'best_r2': max(model_comparison, key=lambda x: x['r2_score'])['r2_score'] if model_comparison else 'unknown'
        }
        
        pd.DataFrame([summary_stats]).to_csv('variable_selection_summary.csv', index=False, encoding='utf-8')
        
        print(f"\nðŸŽ¯ ì¢…í•© ë¶„ì„ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ:")
        print(f"   - ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ: model_performance_comparison.csv")
        print(f"   - ì¢…í•© ë³€ìˆ˜ ë¶„ì„: comprehensive_feature_analysis.csv") 
        print(f"   - ì „ì²´ ìš”ì•½: variable_selection_summary.csv")
        print(f"   - ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {summary_stats['best_model']} (RÂ²: {summary_stats['best_r2']:.3f})") 